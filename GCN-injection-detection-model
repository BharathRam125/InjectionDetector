{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11007604,"sourceType":"datasetVersion","datasetId":6852857}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n!pip install nltk pandas scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T16:28:06.459767Z","iopub.execute_input":"2025-03-12T16:28:06.460084Z","iopub.status.idle":"2025-03-12T16:28:16.311395Z","shell.execute_reply.started":"2025-03-12T16:28:06.460057Z","shell.execute_reply":"2025-03-12T16:28:16.310567Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-geometric, torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt20cpu torch-geometric-2.6.1 torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pickle\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom torch_geometric.data import Data, Dataset, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom IPython.display import FileLink\n\n# Install necessary libraries\nprint(\"[INFO] Installing required libraries...\")\n!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html > /dev/null 2>&1\n!pip install nltk pandas scikit-learn > /dev/null 2>&1\n\n# Download NLTK tokenizer\nprint(\"[INFO] Downloading NLTK tokenizer...\")\nnltk.download(\"punkt\")\n\n# Create output directory\nSAVE_DIR = \"/kaggle/working/saved_data\"\nos.makedirs(SAVE_DIR, exist_ok=True)\nprint(f\"[INFO] Save directory created at {SAVE_DIR}\")\n\n# 1. Dataset Class =============================================================\nclass PayloadDataset(Dataset):\n    def __init__(self, csv_path, save_dir=SAVE_DIR):\n        super().__init__()\n        self.save_dir = save_dir\n        print(\"[INFO] Loading dataset...\")\n        \n        # Load and clean data\n        self.df = pd.read_csv(csv_path)\n        self._clean_data()\n        \n        self.vocab = None\n        self.train_df = None\n        self.val_df = None\n        \n        try:\n            self.load_preprocessed()\n            print(\"[INFO] Loaded preprocessed data from disk ✅\")\n        except FileNotFoundError:\n            print(\"[INFO] Preprocessing dataset...\")\n            self.preprocess_and_save()\n            print(\"[INFO] Preprocessed dataset saved ✅\")\n\n    def _clean_data(self):\n        print(\"[INFO] Cleaning dataset...\")\n        self.df = self.df.dropna(subset=[\"Payload\", \"Label\"])\n        self.df[\"Label\"] = pd.to_numeric(self.df[\"Label\"], errors=\"coerce\").astype(\"Int64\")\n        self.df = self.df.dropna(subset=[\"Label\"])\n        self.df = self.df[self.df[\"Label\"].isin([0, 1])].reset_index(drop=True)\n\n    def preprocess_and_save(self):\n        print(\"[INFO] Tokenizing and building vocabulary...\")\n        self.vocab = defaultdict(lambda: len(self.vocab))\n        self.vocab['<UNK>'] = 0\n        processed_data = []\n\n        for idx, payload in enumerate(self.df[\"Payload\"]):\n            tokens = word_tokenize(str(payload))\n            indices = [self.vocab[token] for token in tokens]\n            processed_data.append({\n                \"Index\": idx,\n                \"Tokenized_Payload\": \" \".join(map(str, indices)),\n                \"Label\": self.df[\"Label\"][idx]\n            })\n\n        print(\"[INFO] Saving vocabulary...\")\n        self.vocab = dict(self.vocab)\n        with open(f\"{self.save_dir}/vocab.pkl\", \"wb\") as f:\n            pickle.dump(self.vocab, f)\n\n        print(\"[INFO] Saving processed dataset...\")\n        processed_df = pd.DataFrame(processed_data)\n        processed_df.to_csv(f\"{self.save_dir}/processed_dataset.csv\", index=False)\n\n        print(\"[INFO] Splitting dataset into training and validation sets...\")\n        self.train_df, self.val_df = train_test_split(\n            self.df, test_size=0.2, random_state=42\n        )\n        self.train_df.to_csv(f\"{self.save_dir}/train.csv\", index=False)\n        self.val_df.to_csv(f\"{self.save_dir}/val.csv\", index=False)\n\n    def load_preprocessed(self):\n        print(\"[INFO] Loading preprocessed dataset from disk...\")\n        with open(f\"{self.save_dir}/vocab.pkl\", \"rb\") as f:\n            self.vocab = pickle.load(f)\n        self.train_df = pd.read_csv(f\"{self.save_dir}/train.csv\")\n        self.val_df = pd.read_csv(f\"{self.save_dir}/val.csv\")\n\n    def __len__(self):\n        return len(self.train_df)\n\n    def __getitem__(self, idx):\n        row = self.train_df.iloc[idx]\n        payload = row[\"Payload\"]\n        label = int(row[\"Label\"])\n\n        tokens = word_tokenize(str(payload))\n        indices = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n\n        edge_index = []\n        for i in range(len(tokens)-1):\n            edge_index.extend([[i, i+1], [i+1, i]])\n\n        return Data(\n            x=torch.tensor(indices, dtype=torch.long).unsqueeze(1),\n            edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n            y=torch.tensor(label, dtype=torch.float)\n        )\n\n# 2. GCN Model =================================================================\nclass MaliciousGCN(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64):\n        super().__init__()\n        print(\"[INFO] Initializing GCN model...\")\n        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n        self.conv1 = GCNConv(embedding_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.classifier = torch.nn.Linear(hidden_dim, 1)\n\n    def forward(self, data):\n        x = self.embedding(data.x.squeeze(1))\n        x = self.conv1(x, data.edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, data.edge_index)\n        x = global_mean_pool(x, batch=torch.zeros(x.size(0), dtype=torch.long))\n        return torch.sigmoid(self.classifier(x)).squeeze()  # ✅ FIXED: Remove extra dim\n\n\n# 3. Training & Saving =========================================================\ndef train_and_save(csv_path=\"/kaggle/input/sqli-xss-payload-dataset-for-waf/dataset.csv\", save_dir=SAVE_DIR):\n    print(\"[INFO] Initializing dataset...\")\n    dataset = PayloadDataset(csv_path, save_dir)\n    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n    print(\"[INFO] Initializing GCN model...\")\n    model = MaliciousGCN(vocab_size=len(dataset.vocab))\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch.nn.BCELoss()\n\n    print(\"[INFO] Starting training process...\")\n    best_acc = 0\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in loader:\n            optimizer.zero_grad()\n            out = model(batch)  # Output shape: [batch_size]\n            loss = criterion(out, batch.y.float())  # ✅ FIXED: Ensure float type\n            loss.backward()\n            optimizer.step()\n\n\n        # Validation\n        model.eval()\n        val_correct = 0\n        with torch.no_grad():\n            for _, row in dataset.val_df.iterrows():\n                data = dataset.__getitem__(row.name)\n                pred = (model(data) > 0.5).float()\n                val_correct += (pred == data.y).sum().item()\n\n        val_acc = val_correct / len(dataset.val_df)\n        if val_acc > best_acc:\n            torch.save({\n                \"model_state\": model.state_dict(),\n                \"vocab\": dataset.vocab\n            }, f\"{save_dir}/best_model.pth\")\n            best_acc = val_acc\n            print(f\"[INFO] Saved new best model with accuracy: {best_acc:.4f} ✅\")\n\n        print(f\"[INFO] Epoch {epoch+1:03d} | Loss: {total_loss/len(loader):.4f} | Val Acc: {val_acc:.4f}\")\n\n    print(\"[INFO] Training complete! Model and dataset saved ✅\")\n\n# 4. Run Training ==============================================================\nif __name__ == \"__main__\":\n    train_and_save(\"/kaggle/input/sqli-xss-payload-dataset-for-waf/dataset.csv\")\n\n    print(\"[INFO] Download Processed Dataset:\")\n    display(FileLink(f\"{SAVE_DIR}/processed_dataset.csv\"))\n\n    print(\"[INFO] Download Trained Model:\")\n    display(FileLink(f\"{SAVE_DIR}/best_model.pth\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-12T15:45:46.473041Z","iopub.execute_input":"2025-03-12T15:45:46.473406Z","iopub.status.idle":"2025-03-12T15:45:53.590396Z","shell.execute_reply.started":"2025-03-12T15:45:46.473380Z","shell.execute_reply":"2025-03-12T15:45:53.589203Z"}},"outputs":[{"name":"stdout","text":"[INFO] Installing required libraries...\n[INFO] Downloading NLTK tokenizer...\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[INFO] Save directory created at /kaggle/working/saved_data\n[INFO] Initializing dataset...\n[INFO] Loading dataset...\n[INFO] Cleaning dataset...\n[INFO] Loading preprocessed dataset from disk...\n[INFO] Loaded preprocessed data from disk ✅\n[INFO] Initializing GCN model...\n[INFO] Initializing GCN model...\n[INFO] Starting training process...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-bb0262fed894>\u001b[0m in \u001b[0;36m<cell line: 184>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;31m# 4. Run Training ==============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mtrain_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/sqli-xss-payload-dataset-for-waf/dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Download Processed Dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-bb0262fed894>\u001b[0m in \u001b[0;36mtrain_and_save\u001b[0;34m(csv_path, save_dir)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output shape: [batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ✅ FIXED: Ensure float type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         return F.binary_cross_entropy(\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3543\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3545\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3546\u001b[0m             \u001b[0;34mf\"Using a target size ({target.size()}) that is different to the input size ({input.size()}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size."],"ename":"ValueError","evalue":"Using a target size (torch.Size([32])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\n\n# ✅ 1. Load & Shuffle Dataset\nprint(\"[INFO] Loading dataset...\")\ndf = pd.read_csv(\"/kaggle/input/sqli-xss-payload-dataset-for-waf/dataset.csv\")\n\n# ✅ Ensure 'Payload' is a string, replace NaN with an empty string\ndf[\"Payload\"] = df[\"Payload\"].astype(str).fillna(\"\")\n\n# ✅ Remove non-numeric labels\ndf = df[pd.to_numeric(df[\"Label\"], errors=\"coerce\").notna()]\ndf[\"Label\"] = df[\"Label\"].astype(int)  # Convert Label to integer\n\n# ✅ Normalize Labels (Ensure [0,1] Range)\ndf[\"Label\"] = (df[\"Label\"] - df[\"Label\"].min()) / (df[\"Label\"].max() - df[\"Label\"].min())\n\n# ✅ Shuffle dataset\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\nprint(\"[INFO] Dataset Loaded & Shuffled ✅\")\n\n# ✅ 2. Graph Conversion\ndef text_to_graph(text):\n    words = list(set(text.split()))  # Unique words as nodes\n\n    if len(words) == 0:\n        return [], torch.empty((2, 0), dtype=torch.long)  # Handle empty cases\n\n    edges = [(i, j) for i in range(len(words)) for j in range(i+1, len(words))]  # Fully connected graph\n    edge_index = torch.tensor(edges, dtype=torch.long).t() if edges else torch.empty((2, 0), dtype=torch.long)\n    \n    return words, edge_index\n\ngraphs = []\n\nfor _, row in df.iterrows():\n    payload, label = row[\"Payload\"], row[\"Label\"]\n    nodes, edge_index = text_to_graph(payload)\n\n    if len(nodes) == 0:\n        continue  # ✅ Skip empty graphs\n\n    x = torch.ones(len(nodes), 16) * 0.01  # ✅ Small uniform values\n\n    y = torch.tensor([float(label)], dtype=torch.float)  # ✅ Ensure float label\n\n    graphs.append(Data(x=x, edge_index=edge_index, y=y))\n\nprint(\"[INFO] Graphs Created ✅\")\n\n# ✅ 3. Train-Test Split\ntrain_graphs, test_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\nprint(f\"[INFO] Training samples: {len(train_graphs)}, Testing samples: {len(test_graphs)}\")\n\n# ✅ Save Train & Test Data\ntorch.save(train_graphs, \"/kaggle/working/train_graphs.pt\")\ntorch.save(test_graphs, \"/kaggle/working/test_graphs.pt\")\nprint(\"[INFO] Train & Test Data Saved ✅\")\n\nclass SimpleGCN(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim=16):\n        super().__init__()\n        print(\"[INFO] Initializing Simple GCN Model...\")\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, 1)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)  # ✅ No Sigmoid, since loss function handles it\n        return x.mean(dim=0)\n\n# ✅ 5. Train Model\nmodel = SimpleGCN(input_dim=graphs[0].x.shape[1])\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)  # ✅ Lowered LR\ncriterion = torch.nn.BCEWithLogitsLoss()\n\nprint(\"[INFO] Starting Training...\")\nfor epoch in range(10):  # 10 epochs\n    total_loss, correct_train, total_train = 0, 0, 0\n    correct_test, total_test = 0, 0\n    \n    # Training\n    model.train()\n    for graph in train_graphs:\n        optimizer.zero_grad()\n        out = model(graph).view(-1)\n\n        if torch.isnan(out).any():\n            print(\"[ERROR] NaN detected in model output! Skipping...\")\n            continue  # ✅ Skip bad samples\n        \n        loss = criterion(out, graph.y)\n\n        if torch.isnan(loss):\n            print(\"[ERROR] NaN loss detected! Skipping...\")\n            continue\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)  # ✅ Stronger Clipping\n        optimizer.step()\n        total_loss += loss.item()\n        \n        preds = (torch.sigmoid(out) >= 0.5).float()  # ✅ Apply sigmoid for predictions\n        correct_train += (preds == graph.y).sum().item()\n        total_train += len(graph.y)\n\n    train_acc = correct_train / total_train * 100 if total_train > 0 else 0\n\n    # Testing\n    model.eval()\n    with torch.no_grad():\n        for graph in test_graphs:\n            out = model(graph).view(-1)\n            preds = (torch.sigmoid(out) >= 0.5).float()\n            correct_test += (preds == graph.y).sum().item()\n            total_test += len(graph.y)\n\n    test_acc = correct_test / total_test * 100 if total_test > 0 else 0\n\n    print(f\"[INFO] Epoch {epoch+1}/10 - Loss: {total_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n\nprint(\"[INFO] Training Completed ✅\")\n\n# ✅ 6. Save Model\ntorch.save(model.state_dict(), \"/kaggle/working/simple_gcn.pth\")\nprint(\"[INFO] Model Saved ✅\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T16:52:40.424887Z","iopub.execute_input":"2025-03-12T16:52:40.425182Z"}},"outputs":[{"name":"stdout","text":"[INFO] Loading dataset...\n[INFO] Dataset Loaded & Shuffled ✅\n[INFO] Graphs Created ✅\n[INFO] Training samples: 35589, Testing samples: 8898\n[INFO] Train & Test Data Saved ✅\n[INFO] Initializing Simple GCN Model...\n[INFO] Starting Training...\n[INFO] Epoch 1/10 - Loss: 24512.6259, Train Acc: 57.62%, Test Acc: 58.72%\n[INFO] Epoch 2/10 - Loss: 24521.2284, Train Acc: 57.62%, Test Acc: 58.72%\n[INFO] Epoch 3/10 - Loss: 24521.2284, Train Acc: 57.62%, Test Acc: 58.72%\n","output_type":"stream"}],"execution_count":null}]}